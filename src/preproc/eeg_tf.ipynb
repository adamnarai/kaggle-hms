{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-frequency transform of eeg data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "mne.viz.set_browser_backend('matplotlib')\n",
    "\n",
    "# Params\n",
    "sfreq = 200\n",
    "n_jobs = 32\n",
    "n_cycles = 10.0\n",
    "freqs = np.arange(0.5, 20, 0.25)\n",
    "ch_list = ['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n",
    "ch_pairs = [('Fp1', 'F7'), ('F7', 'T3'), ('T3', 'T5'), ('T5', 'O1'), \n",
    "            ('Fp2', 'F8'), ('F8', 'T4'), ('T4', 'T6'), ('T6', 'O2'), \n",
    "            ('Fp1', 'F3'), ('F3', 'C3'), ('C3', 'P3'), ('P3', 'O1'), \n",
    "            ('Fp2', 'F4'), ('F4', 'C4'), ('C4', 'P4'), ('P4', 'O2'), \n",
    "            ('Fz', 'Cz'), ('Cz', 'Pz')]\n",
    "bundles = [('Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1'), \n",
    "           ('Fp2-F8', 'F8-T4', 'T4-T6', 'T6-O2'), \n",
    "           ('Fp1-F3', 'F3-C3', 'C3-P3', 'P3-O1'), \n",
    "           ('Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2'), \n",
    "           ('Fz-Cz', 'Cz-Pz'),\n",
    "           ('EKG',)]\n",
    "sub_ch_list = ['-'.join(pair) for pair in ch_pairs]\n",
    "\n",
    "eeg_tf_type = '' # Use 0.7 Hz tf resolution, 0.5-00 Hz range, morlet wavelet\n",
    "# eeg_tf_type = '_bundles' # Use 6 bundles based on rater images, 0.25 Hz tf resolution\n",
    "# eeg_tf_type = '_bundles_multitaper' # Use 6 bundles based on rater images, 0.25 Hz tf resolution, multitaper (instead of morlet)\n",
    "# eeg_tf_type = '_10hz' # Use 0.4 Hz tf resolution, 0.5-10 Hz range\n",
    "# eeg_tf_type = '_30hz' # Use 1.1 Hz tf resolution, 0.5-30 Hz range\n",
    "# eeg_tf_type = '_globalnorm' # Same as '' but with global normalization (ECG normalized separately)\n",
    "# eeg_tf_type = '_bundles_globalnorm' # Same as '_bundles' but with global normalization (ECG normalized separately)\n",
    "# eeg_tf_type = '_bundles_globalnorm_ncycles3' # Same as '_bundles' but with global normalization (ECG normalized separately), n_cycles 3.0\n",
    "eeg_tf_type = '_bundles_globalnorm_ncycles10' # Same as '_bundles' but with global normalization (ECG normalized separately), n_cycles 10.0\n",
    "\n",
    "# Paths\n",
    "root = '/media/latlab/MR/projects/kaggle-hms'\n",
    "data_dir = os.path.join(root, 'data')\n",
    "results_dir = os.path.join(root, 'results')\n",
    "out_dir = os.path.join(data_dir, 'eeg')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "df = df.groupby('eeg_id').head(1).reset_index(drop=True)    # Only keep first row for each eeg_id\n",
    "eeg_data = np.load(os.path.join(data_dir, 'eeg_data.npy'), allow_pickle=True).item()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = df.shape[0] // n_jobs\n",
    "chunks = [df.iloc[df.index[i:i + chunk_size]] for i in range(0, df.shape[0], chunk_size)]\n",
    "\n",
    "def get_tf_data(df):\n",
    "    mne.set_log_level('warning')\n",
    "    eeg_tf_data = dict()\n",
    "    for row in tqdm(df.itertuples(), total=len(df)):\n",
    "        data = eeg_data[row.eeg_id]\n",
    "        data = np.nan_to_num(data, nan=0.0)\n",
    "        arr_list = []\n",
    "        for (ch1, ch2) in ch_pairs:\n",
    "            arr_list.append(data[:,ch_list.index(ch1)] - data[:,ch_list.index(ch2)])\n",
    "        arr_list.append(data[:,ch_list.index('EKG')])\n",
    "        data = np.stack(arr_list, axis=0)\n",
    "\n",
    "        tf_ch_names = sub_ch_list + ['EKG']\n",
    "        raw = mne.io.RawArray(data, mne.create_info(ch_names=tf_ch_names, sfreq=sfreq, ch_types=['eeg']*(len(sub_ch_list)) + ['ecg']))\n",
    "        raw = raw.crop(tmin=0, tmax=0 + 50, include_tmax=False)\n",
    "        data = np.expand_dims(raw.get_data(), axis=0)\n",
    "\n",
    "        tf = mne.time_frequency.tfr_array_morlet(data, sfreq, freqs=freqs, output='power', n_jobs=1, decim=20, n_cycles=n_cycles)\n",
    "        tf = tf.squeeze()\n",
    "\n",
    "        # create bundles\n",
    "        tf_arr_list = []\n",
    "        for i, bundle in enumerate(bundles):\n",
    "            bundle_idx = [tf_ch_names.index(ch) for ch in bundle]\n",
    "            tf_arr_list.append(np.mean(tf[bundle_idx,...], axis=0))\n",
    "        tf = np.stack(tf_arr_list, axis=0)\n",
    "\n",
    "        # log transform\n",
    "        tf = np.log(tf)\n",
    "\n",
    "        # standardize per image\n",
    "        # for i in range(tf.shape[0]):\n",
    "        #     ep = 1e-6\n",
    "        #     m = np.nanmean(tf[i,...].flatten())\n",
    "        #     s = np.nanstd(tf[i,...].flatten())\n",
    "        #     tf[i,...] = (tf[i,...]-m)/(s+ep)\n",
    "        # tf = np.nan_to_num(tf, nan=0.0)\n",
    "        # img = np.reshape(tf, (-1, tf.shape[-1]))\n",
    "\n",
    "        ep = 1e-6\n",
    "        m = np.nanmean(tf[:-1,...].flatten())\n",
    "        s = np.nanstd(tf[:-1,...].flatten())\n",
    "        tf[:-1,...] = (tf[:-1,...]-m)/(s+ep)\n",
    "        m = np.nanmean(tf[[-1],...].flatten())\n",
    "        s = np.nanstd(tf[[-1],...].flatten())\n",
    "        tf[[-1],...] = (tf[[-1],...]-m)/(s+ep)\n",
    "        tf = np.nan_to_num(tf, nan=0.0)\n",
    "        img = np.reshape(tf, (-1, tf.shape[-1]))\n",
    "\n",
    "        eeg_tf_data[row.eeg_id] = img.astype(np.float32)\n",
    "\n",
    "        del raw, data, tf, img\n",
    "\n",
    "    return eeg_tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_tf_data = get_tf_data(df)\n",
    "\n",
    "pool = multiprocessing.Pool(processes=n_jobs)\n",
    "results = pool.map(get_tf_data, chunks)\n",
    "eeg_tf_data = {k: v for d in results for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing single eeg_id\n",
    "# eeg_id = df['eeg_id'].unique()[0]\n",
    "\n",
    "# mne.set_log_level('warning')\n",
    "# data = eeg_data[eeg_id]\n",
    "# data = np.nan_to_num(data, nan=0.0)\n",
    "# arr_list = []\n",
    "# for (ch1, ch2) in ch_pairs:\n",
    "#     arr_list.append(data[:,ch_list.index(ch1)] - data[:,ch_list.index(ch2)])\n",
    "# arr_list.append(data[:,ch_list.index('EKG')])\n",
    "# data = np.stack(arr_list, axis=0)\n",
    "\n",
    "# tf_ch_names = sub_ch_list + ['EKG']\n",
    "# raw = mne.io.RawArray(data, mne.create_info(ch_names=tf_ch_names, sfreq=sfreq, ch_types=['eeg']*(len(sub_ch_list)) + ['ecg']))\n",
    "# raw = raw.crop(tmin=0, tmax=0 + 50, include_tmax=False)\n",
    "# data = np.expand_dims(raw.get_data(), axis=0)\n",
    "\n",
    "# tf = mne.time_frequency.tfr_array_morlet(data, sfreq, freqs=freqs, output='power', n_jobs=n_jobs, decim=20, n_cycles=n_cycles)\n",
    "# tf = tf.squeeze()\n",
    "\n",
    "# # create bundles\n",
    "# tf_arr_list = []\n",
    "# for i, bundle in enumerate(bundles):\n",
    "#     bundle_idx = [tf_ch_names.index(ch) for ch in bundle]\n",
    "#     tf_arr_list.append(np.mean(tf[bundle_idx,...], axis=0))\n",
    "# tf = np.stack(tf_arr_list, axis=0)\n",
    "\n",
    "# # log transform\n",
    "# tf = np.log(tf)\n",
    "\n",
    "# # standardize per image\n",
    "# # for i in range(tf.shape[0]):\n",
    "# #     ep = 1e-6\n",
    "# #     m = np.nanmean(tf[i,...].flatten())\n",
    "# #     s = np.nanstd(tf[i,...].flatten())\n",
    "# #     tf[i,...] = (tf[i,...]-m)/(s+ep)\n",
    "# #     tf[i,...] = np.nan_to_num(tf[i,...], nan=0.0)\n",
    "# # tf = np.nan_to_num(tf, nan=0.0)\n",
    "\n",
    "# ep = 1e-6\n",
    "# m = np.nanmean(tf[:-1,...].flatten())\n",
    "# s = np.nanstd(tf[:-1,...].flatten())\n",
    "# tf[:-1,...] = (tf[:-1,...]-m)/(s+ep)\n",
    "# m = np.nanmean(tf[[-1],...].flatten())\n",
    "# s = np.nanstd(tf[[-1],...].flatten())\n",
    "# tf[[-1],...] = (tf[[-1],...]-m)/(s+ep)\n",
    "# tf = np.nan_to_num(tf, nan=0.0)\n",
    "\n",
    "# img = np.reshape(tf, (-1, tf.shape[-1]))\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(img)\n",
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_dir, f'eeg_tf_data{eeg_tf_type}.npy'), eeg_tf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_data = np.load(os.path.join(data_dir, f'eeg_tf_data{eeg_tf_type}.npy'), allow_pickle=True).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from dataloader import get_dataloaders, get_datasets\n",
    "from utils import seed_everything\n",
    "from train import load_data\n",
    "from config import Config\n",
    "from train import train\n",
    "\n",
    "class CFG(Config):\n",
    "    # resnet18/34/50, efficientnet_b0/b1, convnext_atto/femto/tiny, repvit_m0_9/1_0/1_1/1_5/2_3, efficientvit_b0/b1 tiny_vit_5/11/21m_224\n",
    "    base_model = 'efficientnet_b0'\n",
    "    batch_size = 16\n",
    "    epochs = 30\n",
    "    base_lr = 1e-3\n",
    "    optimizer = 'AdamW'\n",
    "    loss = 'KLDivLoss'\n",
    "    scheduler = 'StepLR'\n",
    "    scheduler_step_size = 2\n",
    "    lr_gamma = 0.1\n",
    "    sgd_momentum = 0.9\n",
    "    freeze_epochs = 0\n",
    "    spec_random_trial_num = 1\n",
    "    eeg_random_trial_num = 1\n",
    "    data_type = 'eeg'  # 'spec', 'eeg_tf', 'spec+eeg_tf'ArithmeticError\n",
    "    eeg_tf_data = 'eeg_tf_data_globalnorm'\n",
    "    train_type = 'rater_num_split'\n",
    "    init_epochs = 15\n",
    "    eeg_ch = 19\n",
    "\n",
    "    # Augmentation\n",
    "    use_mixup = False\n",
    "    mixup_alpha = 2.0\n",
    "    coarse_dropout_args = dict(p=0.5, max_holes=8, max_height=128, max_width=128)\n",
    "    # xy_masking_args = dict(p=0.0, num_masks_x=(2, 6), mask_x_length=(40, 60), fill_value=0.5)\n",
    "    # ringing_overshoot_args = dict(p=0.0)\n",
    "    # median_blur_args = dict(p=0.0)\n",
    "    # sharpen_args = dict(p=0.0)\n",
    "    # time_crop_p = 0.5\n",
    "    # time_crop_args = dict(max_trim=50)\n",
    "    # ch_vertical_flip_args = dict(ch_num=19, p=0.5)\n",
    "\n",
    "    if data_type == 'spec':\n",
    "        in_channels = 1\n",
    "        spec_trial_selection = 'first'\n",
    "        eeg_trial_selection = 'all'\n",
    "    elif data_type == 'eeg_tf' or data_type == 'eeg':\n",
    "        in_channels = 1\n",
    "        spec_trial_selection = 'all'\n",
    "        eeg_trial_selection = 'first'\n",
    "    elif data_type == 'spec+eeg_tf':\n",
    "        spec_trial_selection = 'all'\n",
    "        eeg_trial_selection = 'first'\n",
    "\n",
    "    use_wandb = False\n",
    "    one_fold = True\n",
    "\n",
    "plot_samples = False\n",
    "\n",
    "# Show training data\n",
    "if plot_samples:\n",
    "    seed_everything(CFG.seed)\n",
    "    df, data = load_data(CFG)\n",
    "    dataloaders = get_dataloaders(CFG, get_datasets(CFG, data, df_train=df, df_validation=df))\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloaders['train']):\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            for i in range(len(X)):\n",
    "                # plt.subplot(int(np.ceil(len(X)/6)), 6, i+1)\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                if CFG.data_type == 'eeg':\n",
    "                    raw_data = X[i].cpu().numpy()[...].T\n",
    "                    for k in range(1, len(raw_data)):\n",
    "                        plt.plot(range(raw_data.shape[1]), raw_data[k]-k*(raw_data[0].max()-raw_data[0].min()))\n",
    "                    plt.legend()\n",
    "                    plt.yticks([])\n",
    "                else:\n",
    "                    img_data = X[i].permute(1, 2, 0).cpu().numpy()[...]\n",
    "                    # Normalize images for plotting (since there are negative values in tensors)\n",
    "                    # img_data_norm = np.clip(((img_data - img_data.mean(axis=(0, 1, 2))) / img_data.std(axis=(0, 1, 2)))/4 + 0.5, 0, 1)\n",
    "                    plt.imshow(img_data, vmin=-3, vmax=3, cmap='RdBu_r')\n",
    "                t = y[i].cpu().numpy()\n",
    "                tars = f'[{t[0]:0.2f}'\n",
    "                for s in t[1:]: tars += f', {s:0.2f}'\n",
    "                tars += ']'\n",
    "                plt.title(tars, fontdict={'fontsize': 8})\n",
    "                if i > 0:\n",
    "                    break\n",
    "            if batch >= 0:\n",
    "                break\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation fold 1/5\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [01:16<00:00,  7.83it/s]\n",
      "100%|██████████| 128/128 [00:09<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best kl_divergence: 1.2318\n",
      "Saving model to /media/latlab/MR/projects/kaggle-hms/results/models/hms-debug/hms-debug-cv1.pt\n",
      "lr: [0.001]\n",
      "train loss: 1.0083, test loss: 1.2318, kl_divergence: 1.2318\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [01:16<00:00,  7.83it/s]\n",
      "100%|██████████| 128/128 [00:09<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best kl_divergence: 0.9915\n",
      "Saving model to /media/latlab/MR/projects/kaggle-hms/results/models/hms-debug/hms-debug-cv1.pt\n",
      "lr: [0.0001]\n",
      "train loss: 0.7936, test loss: 0.9915, kl_divergence: 0.9915\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [01:16<00:00,  7.81it/s]\n",
      "100%|██████████| 128/128 [00:09<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best kl_divergence: 0.9885\n",
      "Saving model to /media/latlab/MR/projects/kaggle-hms/results/models/hms-debug/hms-debug-cv1.pt\n",
      "lr: [0.0001]\n",
      "train loss: 0.6666, test loss: 0.9885, kl_divergence: 0.9885\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [01:16<00:00,  7.81it/s]\n",
      "100%|██████████| 128/128 [00:09<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best kl_divergence: 0.9505\n",
      "Saving model to /media/latlab/MR/projects/kaggle-hms/results/models/hms-debug/hms-debug-cv1.pt\n",
      "lr: [1e-05]\n",
      "train loss: 0.6310, test loss: 0.9505, kl_divergence: 0.9505\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [01:16<00:00,  7.80it/s]\n",
      "100%|██████████| 128/128 [00:09<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: [1e-05]\n",
      "train loss: 0.6105, test loss: 0.9703, kl_divergence: 0.9703\n",
      "\n",
      "Training complete in 7m 11s\n",
      "Final kl_divergence: 0.970304\n",
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:36<00:00,  7.49it/s]\n",
      "100%|██████████| 66/66 [00:06<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best kl_divergence: 0.4726\n",
      "Saving model to /media/latlab/MR/projects/kaggle-hms/results/models/hms-debug/hms-debug-cv1.pt\n",
      "lr: [0.001]\n",
      "train loss: 0.4715, test loss: 0.4726, kl_divergence: 0.4726\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 79/273 [00:13<00:32,  6.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/train.py:216\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(CFG)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     wandb_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m best_metric_list\u001b[38;5;241m.\u001b[39mappend(trainer\u001b[38;5;241m.\u001b[39mbest_metric)\n\u001b[1;32m    218\u001b[0m metric_list\u001b[38;5;241m.\u001b[39mappend(trainer\u001b[38;5;241m.\u001b[39mlast_metric)\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/train.py:80\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(CFG, data, df_train, df_validation, state_filename, validate, wandb_log)\u001b[0m\n\u001b[1;32m     78\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mload_best_state()\n\u001b[1;32m     79\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mbest_metric \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf  \u001b[38;5;66;03m# Reset best metric, so only second stage models can be the best\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     trainer\u001b[38;5;241m.\u001b[39msave_state(state_filename)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m CFG\u001b[38;5;241m.\u001b[39mtrain_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# Data loaders\u001b[39;00m\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/trainer/trainer.py:47\u001b[0m, in \u001b[0;36mTrainer.train_epochs\u001b[0;34m(self, num_epochs, validate)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[1;32m     49\u001b[0m     test_loss, metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest()\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/trainer/trainer.py:98\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 98\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(CFG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc-ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

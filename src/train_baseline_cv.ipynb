{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (17089, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_sub_id</th>\n",
       "      <th>eeg_label_offset_seconds</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spectrogram_sub_id</th>\n",
       "      <th>spectrogram_label_offset_seconds</th>\n",
       "      <th>label_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127492639</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2277392603</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978807404</td>\n",
       "      <td>30539</td>\n",
       "      <td>GPD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>722738444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557980729</td>\n",
       "      <td>56885</td>\n",
       "      <td>LRDA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387987538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1084844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4099147263</td>\n",
       "      <td>4264</td>\n",
       "      <td>LRDA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2175806584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1219001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1963161945</td>\n",
       "      <td>23435</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
       "0  1628180742           0                       0.0          353733   \n",
       "1  2277392603           0                       0.0          924234   \n",
       "2   722738444           0                       0.0          999431   \n",
       "3   387987538           0                       0.0         1084844   \n",
       "4  2175806584           0                       0.0         1219001   \n",
       "\n",
       "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
       "0                   0                               0.0   127492639   \n",
       "1                   0                               0.0  1978807404   \n",
       "2                   0                               0.0   557980729   \n",
       "3                   0                               0.0  4099147263   \n",
       "4                   0                               0.0  1963161945   \n",
       "\n",
       "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       42516          Seizure           1.0    0.0000  0.000000      0.000   \n",
       "1       30539              GPD           0.0    0.0000  0.454545      0.000   \n",
       "2       56885             LRDA           0.0    0.0625  0.000000      0.875   \n",
       "3        4264             LRDA           0.0    0.0000  0.000000      1.000   \n",
       "4       23435          Seizure           1.0    0.0000  0.000000      0.000   \n",
       "\n",
       "   grda_vote  other_vote  \n",
       "0   0.000000    0.000000  \n",
       "1   0.090909    0.454545  \n",
       "2   0.000000    0.062500  \n",
       "3   0.000000    0.000000  \n",
       "4   0.000000    0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from ext.kaggle_kl_div.kaggle_kl_div import score as kaggle_kl_div_score\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataloader import get_dataloaders, get_datasets\n",
    "from utils import seed_everything\n",
    "from trainer import Trainer\n",
    "from model.model import SpecCNN\n",
    "from train import load_data, train_model\n",
    "from utils import Config\n",
    "\n",
    "class CFG(Config):\n",
    "    seed = 42\n",
    "    cv_fold = 5\n",
    "    base_model = 'efficientnet_b0'   # resnet18/34/50, efficientnet_b0/b1/b2/b3/b4, efficientnet_v2_s, convnext_tiny, swin_t\n",
    "    batch_size = 32\n",
    "    epochs = 3\n",
    "    base_lr = 1e-3\n",
    "    affine_degrees = 0\n",
    "    affine_translate = None\n",
    "    affine_scale = None\n",
    "    dataloader_num_workers = 8\n",
    "    scheduler_step_size = 2\n",
    "    optimizer = 'AdamW'\n",
    "    scheduler = 'StepLR'\n",
    "    loss = 'KLDivLoss'\n",
    "    lr_gamma = 0.1\n",
    "    sgd_momentum = 0.9\n",
    "    color_jitter_args = dict(p=0.0, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "    random_erasing_p = 0\n",
    "    freeze_epochs = 0\n",
    "    spec_trial_selection = 'all' # 'all', 'first', 'mean_offset'\n",
    "    eeg_trial_selection = 'first'\n",
    "    spec_random_trial_num = 1\n",
    "    TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    coarse_dropout_args = dict(p=0.0, max_holes=8, max_height=64, max_width=64)\n",
    "    data_type = 'spec+eeg_tf'  # 'spec', 'eeg_tf', 'spec+eeg_tf\n",
    "\n",
    "    if data_type == 'spec':\n",
    "        in_channels = 1\n",
    "    elif data_type == 'eeg_tf':\n",
    "        in_channels = 1\n",
    "    elif data_type == 'spec+eeg_tf':\n",
    "        in_channels = 2\n",
    "\n",
    "tags=['torch', 'cv', 'best_epoch']\n",
    "notes = ''\n",
    "plot_samples = False\n",
    "train_final_model = False\n",
    "use_wandb = False\n",
    "one_fold = True\n",
    "\n",
    "# Wandb\n",
    "if use_wandb:\n",
    "    wandb.login(key='1b0401db7513303bdea77fb070097f9d2850cf3b')\n",
    "    run = wandb.init(project='kaggle-hms', config=CFG.get_dict(), tags=tags, notes=notes)\n",
    "else:\n",
    "    WandbRun = namedtuple('WandbRun', 'name')\n",
    "    run = WandbRun('debug')\n",
    "\n",
    "# Label encoder/decoder\n",
    "encode = {'seizure_vote': 0, 'lpd_vote': 1, 'gpd_vote': 2, 'lrda_vote': 3, 'grda_vote': 4, 'other_vote': 5}\n",
    "decode = {v: k for k, v in encode.items()}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "root = '/media/latlab/MR/projects/kaggle-hms'\n",
    "data_dir = os.path.join(root, 'data')\n",
    "results_dir = os.path.join(root, 'results')\n",
    "train_eeg_dir = os.path.join(data_dir, 'train_eegs')\n",
    "train_spectrogram_dir = os.path.join(data_dir, 'train_spectrograms')\n",
    "\n",
    "# Seed\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "# Load data\n",
    "df, data = load_data(CFG)\n",
    "\n",
    "print('Train shape:', df.shape )\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training data\n",
    "if plot_samples:\n",
    "    dataloaders = get_dataloaders(CFG, get_datasets(CFG, data, df_train=df, df_validation=df))\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloaders['train']):\n",
    "            plt.figure(figsize=(np.ceil(len(X)/2), 20))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(int(np.ceil(len(X)/6)), 6, i+1)\n",
    "                # plt.figure()\n",
    "                img_data = X[i].permute(1, 2, 0).cpu().numpy()[..., 1:2]\n",
    "                # Normalize images for plotting (since there are negative values in tensors)\n",
    "                img_data_norm = np.clip(((img_data - img_data.mean(axis=(0, 1, 2))) / img_data.std(axis=(0, 1, 2)))/4 + 0.5, 0, 1)\n",
    "                plt.imshow(img_data_norm)\n",
    "                t = y[i].cpu().numpy()\n",
    "                tars = f'[{t[0]:0.2f}'\n",
    "                for s in t[1:]: tars += f', {s:0.2f}'\n",
    "                tars += ']'\n",
    "                plt.title(tars, fontdict={'fontsize': 8})\n",
    "            if batch >= 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedGroupKFold(n_splits=CFG.cv_fold, random_state=CFG.seed, shuffle=True)\n",
    "metric_list = []\n",
    "targets = []\n",
    "oof_preds = []\n",
    "for cv, (train_index, valid_index) in enumerate(skf.split(X=np.zeros(len(df['expert_consensus'])), y=df['expert_consensus'], groups=df['patient_id'])):\n",
    "    print(f\"Cross-validation fold {cv+1}/{CFG.cv_fold}\")\n",
    "    df_train = df.iloc[train_index]\n",
    "    df_validation = df.iloc[valid_index]\n",
    "    run_name = f'{run.name}-cv{cv+1}'\n",
    "    state_filename = os.path.join(results_dir, 'models', f'ubc-ocean-{run_name}.pt')\n",
    "    if use_wandb and cv == 0:\n",
    "        wandb_log = True\n",
    "    else:\n",
    "        wandb_log = False\n",
    "    trainer = train_model(CFG, data, df_train, df_validation, state_filename, wandb_log=wandb_log)\n",
    "    metric_list.append(trainer.best_metric)\n",
    "    if use_wandb:\n",
    "        wandb.log({f'kl_div_cv{cv+1}': trainer.best_metric})\n",
    "    if one_fold:\n",
    "        break\n",
    "\n",
    "    # Get OOF predictions\n",
    "    targets.append(trainer.test_y)\n",
    "    oof_preds.append(trainer.test_pred)\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.log({f'mean_kl_div': np.mean(metric_list)})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final training on all data\n",
    "if train_final_model:\n",
    "    state_filename = os.path.join(results_dir, 'models', f'ubc-ocean-{run.name}.pt')\n",
    "    trainer = train_model(CFG, data, df, df, state_filename, validate=False, wandb_log=False)\n",
    "    if use_wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion matrix\n",
    "# import warnings\n",
    "# from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "# loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "# datasets = get_tiles_datasets(CFG, train_image_dir, df_train, df_validation[df_validation['is_tma']==True])\n",
    "# dataloaders = get_dataloaders(CFG, datasets)\n",
    "# y_list = []\n",
    "# pred_list = []\n",
    "# loss_list = []\n",
    "# metric = 0\n",
    "# with torch.no_grad():\n",
    "#     for X, y in dataloaders['validation']:\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "#         outputs = model(X)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         loss = loss_fn(outputs, y)\n",
    "#         y_list.append(y.cpu().numpy())\n",
    "#         pred_list.append(preds.cpu().numpy())\n",
    "#         loss_list.append(loss.cpu().numpy())\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter('ignore', category=UserWarning)\n",
    "#             metric += balanced_accuracy_score(y.cpu().numpy(), preds.cpu().numpy())\n",
    "# metric /= len(dataloaders['validation'])\n",
    "# y_list = np.concatenate(y_list)\n",
    "# pred_list = np.concatenate(pred_list)\n",
    "# loss_list = np.concatenate(loss_list)\n",
    "\n",
    "# from ext.pretty_confusion_matrix import pp_matrix\n",
    "# cm = confusion_matrix(y_list, pred_list)\n",
    "# df_cm = pd.DataFrame(cm, index=encode.keys(), columns=encode.keys())\n",
    "# pp_matrix(df_cm, pred_val_axis='x', cmap='Oranges', figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Top k losses\n",
    "# k = 10\n",
    "# topk_loss_idx = list(loss_list.argsort()[-k:])\n",
    "# with torch.no_grad():\n",
    "#     for b, (X, y) in enumerate(dataloaders['validation']):\n",
    "#         for bi in range(len(X)):\n",
    "#             i = b * CFG.batch_size + bi\n",
    "#             if i not in topk_loss_idx:\n",
    "#                 continue\n",
    "#             plt.figure()\n",
    "#             plt.imshow(X[bi].permute(1, 2, 0))\n",
    "#             plt.title(f'loss: {loss_list[i]:.4f}, label: {decode[y_list[i]]}, pred: {decode[pred_list[i]]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubc-ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

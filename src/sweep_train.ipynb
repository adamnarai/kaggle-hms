{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "Training with epochs 3, scheduler StepLR, base_model: resnet34, spec_trial_selection: mean_offset\n",
      "##########################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaraiadam88\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/latlab/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/latlab/MR/projects/kaggle-hms/src/wandb/run-20240127_181020-a9xngmmr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/naraiadam88/kaggle-hms/runs/a9xngmmr' target=\"_blank\">woven-spaceship-83</a></strong> to <a href='https://wandb.ai/naraiadam88/kaggle-hms' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/naraiadam88/kaggle-hms' target=\"_blank\">https://wandb.ai/naraiadam88/kaggle-hms</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/naraiadam88/kaggle-hms/runs/a9xngmmr' target=\"_blank\">https://wandb.ai/naraiadam88/kaggle-hms/runs/a9xngmmr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation fold 1/5\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 49/430 [00:06<00:48,  7.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m CFG\u001b[38;5;241m.\u001b[39mspec_trial_selection \u001b[38;5;241m=\u001b[39m spec_trial_selection\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m##########################\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining with epochs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, scheduler \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, base_model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, spec_trial_selection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec_trial_selection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m##########################\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnotes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_final_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_final_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_wandb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mone_fold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/train.py:129\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(CFG, tags, notes, train_final_model, use_wandb, one_fold)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     wandb_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m metric_list\u001b[38;5;241m.\u001b[39mappend(trainer\u001b[38;5;241m.\u001b[39mbest_metric)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_wandb:\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/train.py:64\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(CFG, spec_data, df_train, df_validation, state_filename, validate, wandb_log)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     63\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, dataloaders, loss_fn, optimizer, scheduler, device, state_filename\u001b[38;5;241m=\u001b[39mstate_filename, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_divergence\u001b[39m\u001b[38;5;124m'\u001b[39m, wandb_log\u001b[38;5;241m=\u001b[39mwandb_log)\n\u001b[0;32m---> 64\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_state(state_filename)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/trainer/trainer.py:45\u001b[0m, in \u001b[0;36mTrainer.train_epochs\u001b[0;34m(self, num_epochs, validate)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[1;32m     47\u001b[0m     test_loss, metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest()\n",
      "File \u001b[0;32m/media/latlab/MR/projects/kaggle-hms/src/trainer/trainer.py:88\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 88\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "from utils import Config\n",
    "\n",
    "class CFG(Config):\n",
    "    seed = 42\n",
    "    cv_fold = 5\n",
    "    base_model = 'resnet34'   # resnet18/34/50, efficientnet_b0/b1/b2/b3/b4, efficientnet_v2_s, convnext_tiny, swin_t\n",
    "    batch_size = 32\n",
    "    epochs = 3\n",
    "    base_lr = 1e-3\n",
    "    affine_degrees = 0\n",
    "    affine_translate = None\n",
    "    affine_scale = None\n",
    "    dataloader_num_workers = 8\n",
    "    scheduler_step_size = 2\n",
    "    optimizer = 'AdamW'\n",
    "    scheduler = 'StepLR'\n",
    "    loss = 'KLDivLoss'\n",
    "    lr_gamma = 0.1\n",
    "    sgd_momentum = 0.9\n",
    "    color_jitter = {'brightness': 0, 'contrast': 0, 'saturation': 0, 'hue': 0}\n",
    "    random_erasing_p = 0\n",
    "    freeze_epochs = 0\n",
    "    in_channels = 1\n",
    "    spec_trial_selection = 'all' # 'all', 'first', 'mean_offset'\n",
    "    TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "\n",
    "tags=['torch', 'cv', 'best_epoch']\n",
    "notes = ''\n",
    "train_final_model = True\n",
    "use_wandb = True\n",
    "one_fold = False\n",
    "\n",
    "for base_model in ['resnet34']:\n",
    "    CFG.base_model = base_model\n",
    "    for epochs in [3, 4]:\n",
    "        CFG.epochs = epochs\n",
    "        for scheduler in ['StepLR', 'CosineAnnealingLR', 'OneCycleLR']:\n",
    "            CFG.scheduler = scheduler\n",
    "            for spec_trial_selection in ['first', 'mean_offset', 'all']:\n",
    "                CFG.spec_trial_selection = spec_trial_selection\n",
    "                print(f'##########################\\nTraining with epochs {epochs}, scheduler {scheduler}, base_model: {base_model}, spec_trial_selection: {spec_trial_selection}\\n##########################\\n')\n",
    "                train(CFG, tags=tags, notes=notes, train_final_model=train_final_model, use_wandb=use_wandb, one_fold=one_fold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('..')\n",
    "from config import Config\n",
    "from utils import seed_everything\n",
    "from train import load_data\n",
    "from dataloader import get_dataloaders, get_datasets\n",
    "from model.model import SpecCNN\n",
    "from ext.kaggle_kl_div.kaggle_kl_div import score as kaggle_kl_div_score\n",
    "\n",
    "\n",
    "class CFG(Config):\n",
    "    model_name = 'red-chrysanthemum-258'\n",
    "    base_model = 'efficientnet_b0'   # resnet18/34/50, efficientnet_b0/b1/b2/b3/b4, efficientnet_v2_s, convnext_tiny, swin_t\n",
    "    batch_size = 32\n",
    "    data_type = 'eeg_tf'\n",
    "    eeg_tf_data = 'eeg_tf_data_globalnorm'\n",
    "    spec_trial_selection = 'all'\n",
    "    eeg_trial_selection = 'all'\n",
    "    coarse_dropout_args = {}\n",
    "    pretrained = False\n",
    "\n",
    "    if data_type == 'spec':\n",
    "        in_channels = 1\n",
    "    elif data_type == 'eeg_tf':\n",
    "        in_channels = 1\n",
    "    elif data_type == 'spec+eeg_tf':\n",
    "        in_channels = 2\n",
    "\n",
    "\n",
    "full_model_name = f'{CFG.project_name}-{CFG.model_name}'\n",
    "model_dir = os.path.join(CFG.models_dir, full_model_name)\n",
    "diag_dir = os.path.join(model_dir, 'diag')\n",
    "if os.path.exists(model_dir):\n",
    "    os.makedirs(diag_dir, exist_ok=True)\n",
    "\n",
    "# Load splits\n",
    "df = pd.read_csv(os.path.join(model_dir, 'splits.csv'))\n",
    "\n",
    "# Load models\n",
    "model_paths = []\n",
    "for fold in range(CFG.cv_fold):\n",
    "    path = os.path.join(model_dir, f'{full_model_name}-cv{fold+1}_best.pt')\n",
    "    assert os.path.exists(path), f'Model {path} does not exist'\n",
    "    model_paths.append(path)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "_, data = load_data(CFG)\n",
    "\n",
    "print(model_paths)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OOF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = []\n",
    "pred_all = []\n",
    "for fold in tqdm(range(1, CFG.cv_fold+1)):\n",
    "    # Get data\n",
    "    df_fold = df[df['fold']==fold]\n",
    "    df_train = df_fold[df_fold['split']=='train']\n",
    "    df_validation = df_fold[df_fold['split']=='validation']\n",
    "    dataloaders = get_dataloaders(CFG, get_datasets(CFG, data, df_train=df_train, df_validation=df_validation))\n",
    "\n",
    "    # Load model\n",
    "    model = SpecCNN(model_name=CFG.base_model, num_classes=len(CFG.TARGETS), in_channels=CFG.in_channels).to(device)\n",
    "    model.load_state_dict(torch.load(model_paths[fold-1]))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        for b, (X, y) in enumerate(dataloaders['validation']):\n",
    "            pred = model(X.to(device))\n",
    "            pred = F.softmax(pred, dim=-1).cpu().numpy()\n",
    "            y_all.append(y.numpy())\n",
    "            pred_all.append(pred)\n",
    "y_all = np.concatenate(y_all)\n",
    "pred_all = np.concatenate(pred_all)\n",
    "\n",
    "y_label = np.argmax(y_all, axis=1)\n",
    "pred_label = np.argmax(pred_all, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for X, y in dataloaders['validation']:\n",
    "        break\n",
    "sample_data = X[0].squeeze()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sample_data)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sample_data, cmap='RdBu_r', vmin=-3, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_df = pd.DataFrame(y_all)\n",
    "y_all_df['id'] = np.arange(len(y_all_df))\n",
    "\n",
    "pred_all_df = pd.DataFrame(pred_all)\n",
    "pred_all_df['id'] = np.arange(len(pred_all_df))\n",
    "\n",
    "metric = kaggle_kl_div_score(submission=pred_all_df, solution=y_all_df, row_id_column_name='id')\n",
    "print(f'Kaggle KL Divergence: {metric:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from ext.pretty_confusion_matrix import pp_matrix\n",
    "\n",
    "cm = confusion_matrix(y_label, pred_label)\n",
    "df_cm = pd.DataFrame(cm, index=CFG.TARGETS, columns=CFG.TARGETS)\n",
    "pp_matrix(df_cm, pred_val_axis='x', cmap='rocket_r', figsize=(8, 8))\n",
    "plt.savefig(os.path.join(diag_dir, 'confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "fold = 1\n",
    "\n",
    "# Get data\n",
    "df_fold = df[df['fold']==fold]\n",
    "df_train = df_fold[df_fold['split']=='train']\n",
    "df_validation = df_fold[df_fold['split']=='validation']\n",
    "dataloaders = get_dataloaders(CFG, get_datasets(CFG, data, df_train=df_train, df_validation=df_validation))\n",
    "\n",
    "# Load model\n",
    "model = SpecCNN(model_name=CFG.base_model, num_classes=len(CFG.TARGETS), in_channels=CFG.in_channels).to(device)\n",
    "model.load_state_dict(torch.load(model_paths[fold-1]))\n",
    "model.to(device)\n",
    "model.eval();\n",
    "\n",
    "target_layers = [model.model.conv_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    for b, (X, y) in enumerate(dataloaders['validation']):\n",
    "        pred = model(X.to(device))\n",
    "        pred = F.softmax(pred, dim=-1).cpu().numpy()\n",
    "        break\n",
    "\n",
    "grayscale_cam = cam(input_tensor=X, targets=[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(sample_data, grayscale_cam, use_rgb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

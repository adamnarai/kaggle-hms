{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('..')\n",
    "from config import Config\n",
    "from utils import seed_everything\n",
    "from train import load_data\n",
    "from dataloader import get_dataloaders, get_datasets\n",
    "from model.model import SpecCNN\n",
    "from ext.kaggle_kl_div.kaggle_kl_div import score as kaggle_kl_div_score\n",
    "\n",
    "\n",
    "class CFG(Config):\n",
    "    model_name = 'decent-galaxy-454' # treasured-river-477\n",
    "    base_model = 'efficientnet_b0'   # resnet18/34/50, efficientnet_b0/b1/b2/b3/b4, efficientnet_v2_s, convnext_tiny, swin_t\n",
    "    batch_size = 16\n",
    "    epochs = 3\n",
    "    base_lr = 1e-3\n",
    "    scheduler_step_size = 2\n",
    "    optimizer = 'Adan'\n",
    "    scheduler = 'StepLR'\n",
    "    loss = 'KLDivLoss'\n",
    "    lr_gamma = 0.1\n",
    "    sgd_momentum = 0.9\n",
    "    random_erasing_p = 0\n",
    "    freeze_epochs = 0\n",
    "    spec_random_trial_num = 1\n",
    "    eeg_random_trial_num = 1\n",
    "    data_type = 'eeg_tf'  # 'spec', 'eeg_tf', 'spec+eeg_tf\n",
    "    eeg_tf_data = 'eeg_tf_data_globalnorm'\n",
    "\n",
    "    # Augmentation\n",
    "    random_ch_erease_args = dict(p=0.0, eeg_ch_num=4, drop_ch_num=1)\n",
    "    random_time_masking_args = dict(p=0.0, width_prop=0.1, erase_num=2)\n",
    "    random_frequency_masking_args = dict(p=0.0, eeg_ch_num=4, bandwidth_prop=0.1, erase_num=1)\n",
    "    use_mixup = False\n",
    "    mixup_alpha = 2.0\n",
    "    coarse_dropout_args = dict(p=0.5, max_holes=8, max_height=128, max_width=128)\n",
    "    time_crop_p = 0.5\n",
    "    time_crop_args = dict(max_trim=150)\n",
    "\n",
    "    if data_type == 'spec':\n",
    "        in_channels = 1\n",
    "        spec_trial_selection = 'first'\n",
    "        eeg_trial_selection = 'all'\n",
    "    elif data_type == 'eeg_tf':\n",
    "        in_channels = 1\n",
    "        spec_trial_selection = 'all'\n",
    "        eeg_trial_selection = 'first'\n",
    "    elif data_type == 'spec+eeg_tf':\n",
    "        spec_trial_selection = 'all'\n",
    "        eeg_trial_selection = 'first'\n",
    "\n",
    "\n",
    "full_model_name = f'{CFG.project_name}-{CFG.model_name}'\n",
    "model_dir = os.path.join(CFG.models_dir, full_model_name)\n",
    "diag_dir = os.path.join(model_dir, 'diag')\n",
    "if os.path.exists(model_dir):\n",
    "    os.makedirs(diag_dir, exist_ok=True)\n",
    "\n",
    "# Load splits\n",
    "df = pd.read_csv(os.path.join(model_dir, 'splits.csv'))\n",
    "\n",
    "# Load models\n",
    "model_paths = []\n",
    "for fold in range(CFG.cv_fold):\n",
    "    path = os.path.join(model_dir, f'{full_model_name}-cv{fold+1}_best.pt')\n",
    "    assert os.path.exists(path), f'Model {path} does not exist'\n",
    "    model_paths.append(path)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "_, data = load_data(CFG)\n",
    "\n",
    "print(model_paths)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get OOF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = []\n",
    "pred_all = []\n",
    "df_test = pd.DataFrame()\n",
    "for fold in tqdm(range(1, CFG.cv_fold+1)):\n",
    "    # Get data\n",
    "    df_fold = df[df['fold']==fold]\n",
    "    df_train = df_fold[df_fold['split']=='train']\n",
    "    df_validation = df_fold[df_fold['split']=='validation']\n",
    "    df_test = pd.concat([df_test, df_validation])\n",
    "    dataloaders = get_dataloaders(CFG, get_datasets(CFG, data, df_train=df_train, df_validation=df_validation))\n",
    "\n",
    "    # Load model\n",
    "    model = SpecCNN(model_name=CFG.base_model, num_classes=len(CFG.TARGETS), in_channels=CFG.in_channels).to(device)\n",
    "    model.load_state_dict(torch.load(model_paths[fold-1]))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        for b, (X, y) in enumerate(dataloaders['validation']):\n",
    "            pred = model(X.to(device))\n",
    "            pred = F.softmax(pred, dim=-1).cpu().numpy()\n",
    "            y_all.append(y.numpy())\n",
    "            pred_all.append(pred)\n",
    "y_all = np.concatenate(y_all)\n",
    "pred_all = np.concatenate(pred_all)\n",
    "\n",
    "y_label = np.argmax(y_all, axis=1)\n",
    "pred_label = np.argmax(pred_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(CFG.TARGETS, ((pred_all-y_all)**2).mean(0))\n",
    "plt.title('MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.KLDivLoss()\n",
    "loss_all = []\n",
    "for i in range(y_all.shape[0]):\n",
    "    loss_all.append(loss_fn(torch.tensor(pred_all[i]), torch.tensor(y_all[i])).item())\n",
    "df_test['loss'] = loss_all\n",
    "df_test['y'] = y_all.tolist()\n",
    "df_test['pred'] = pred_all.tolist()\n",
    "\n",
    "df_test['rater_group'] = df_test['rater_num'].apply(lambda x: 'high' if x > 8 else 'low')\n",
    "df_test['y_std'] = df_test['y'].apply(lambda x: np.std(x))\n",
    "df_test['y_range'] = df_test['y'].apply(lambda x: np.max(x) - np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_loss_sorted = df_test.sort_values('loss', ascending=False).reset_index(drop=True)\n",
    "df_test_loss_sorted['pred'] = df_test_loss_sorted['pred'].apply(lambda x: [round(i, 2) for i in x])\n",
    "df_test_loss_sorted['y'] = df_test_loss_sorted['y'].apply(lambda x: [round(i, 2) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_test_loss_sorted, x='y_range', bins=100);\n",
    "# plt.xlim(-.166, -.165)\n",
    "\n",
    "len(df_test_loss_sorted[df_test_loss_sorted.y_range==1.0])/len(df_test_loss_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test_loss_sorted\n",
    "test = test[test['loss'].between(-.166, -.165)]\n",
    "test.y.iloc[0]\n",
    "np.std([0.0, 0.9, 0.1, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rater numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(df_test, x='y_range', y='loss', kind='hist')\n",
    "# # sns.lmplot(df_test, x='rater_num', y='loss', row='expert_consensus')\n",
    "\n",
    "# for cons in df_test['expert_consensus'].unique():\n",
    "#     df_test_cons = df_test[df_test['expert_consensus']==cons]\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     sns.jointplot(df_test_cons, x='rater_num', y='loss', kind='hist')\n",
    "#     plt.suptitle(f'{cons}')\n",
    "#     plt.ylim(-0.31, 0.01)\n",
    "#     plt.xlim(0, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(CFG, get_datasets(CFG, data, df_train=df_train, df_validation=df_test_loss_sorted))\n",
    "with torch.no_grad():\n",
    "        for b, (X, y) in enumerate(dataloaders['validation']):\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(int(np.ceil(len(X)/4)), 4, i+1)\n",
    "                # plt.figure(figsize=(10, 10))\n",
    "                img_data = X[i].permute(1, 2, 0).cpu().numpy()[...]\n",
    "                # Normalize images for plotting (since there are negative values in tensors)\n",
    "                # img_data_norm = np.clip(((img_data - img_data.mean(axis=(0, 1, 2))) / img_data.std(axis=(0, 1, 2)))/4 + 0.5, 0, 1)\n",
    "                plt.imshow(img_data, vmin=-3, vmax=3, cmap='RdBu_r')\n",
    "                t = y[i].cpu().numpy()\n",
    "                tars = f'[{t[0]:0.2f}'\n",
    "                for s in t[1:]: tars += f', {s:0.2f}'\n",
    "                tars += ']'\n",
    "                plt.title(tars, fontdict={'fontsize': 8})\n",
    "            if b >= 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for X, y in dataloaders['validation']:\n",
    "        break\n",
    "X -= X.min()\n",
    "X /= X.max()\n",
    "sample_data = X[0].squeeze()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sample_data)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sample_data, cmap='RdBu_r', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_df = pd.DataFrame(y_all)\n",
    "y_all_df['id'] = np.arange(len(y_all_df))\n",
    "\n",
    "pred_all_df = pd.DataFrame(pred_all)\n",
    "pred_all_df['id'] = np.arange(len(pred_all_df))\n",
    "\n",
    "metric = kaggle_kl_div_score(submission=pred_all_df, solution=y_all_df, row_id_column_name='id')\n",
    "print(f'Kaggle KL Divergence: {metric:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from ext.pretty_confusion_matrix import pp_matrix\n",
    "\n",
    "cm = confusion_matrix(y_label, pred_label)\n",
    "df_cm = pd.DataFrame(cm, index=CFG.TARGETS, columns=CFG.TARGETS)\n",
    "pp_matrix(df_cm, pred_val_axis='x', cmap='rocket_r', figsize=(8, 8))\n",
    "plt.savefig(os.path.join(diag_dir, 'confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "fold = 1\n",
    "\n",
    "# Get data\n",
    "df_fold = df[df['fold']==fold]\n",
    "df_train = df_fold[df_fold['split']=='train']\n",
    "df_validation = df_fold[df_fold['split']=='validation']\n",
    "dataloaders = get_dataloaders(CFG, get_datasets(CFG, data, df_train=df_train, df_validation=df_validation))\n",
    "\n",
    "# Load model\n",
    "model = SpecCNN(model_name=CFG.base_model, num_classes=len(CFG.TARGETS), in_channels=CFG.in_channels).to(device)\n",
    "model.load_state_dict(torch.load(model_paths[fold-1]))\n",
    "model.to(device)\n",
    "model.eval();\n",
    "\n",
    "target_layers = [model.model.conv_head]\n",
    "\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "# Inference\n",
    "all_X = []\n",
    "with torch.no_grad():\n",
    "    for b, (X, y) in enumerate(dataloaders['validation']):\n",
    "        all_X.append(X)\n",
    "all_X = torch.cat(all_X)\n",
    "\n",
    "\n",
    "for i in range(len(CFG.TARGETS)):\n",
    "    grayscale_cam = cam(input_tensor=X, targets=[ClassifierOutputTarget(i)]*len(X))\n",
    "\n",
    "    ch = sample_data.numpy().astype(np.float32)\n",
    "    sample_image = np.stack((ch, ch, ch), axis=-1)\n",
    "    visualization = show_cam_on_image(sample_image, grayscale_cam.mean(0), use_rgb=True)\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(grayscale_cam)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(visualization)\n",
    "    plt.title(CFG.TARGETS[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
